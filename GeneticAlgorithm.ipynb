{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqlnUGwHT_Gu"
   },
   "source": [
    "Libreries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_gs=True\n",
    "# define the grid search parameters and variables\n",
    "\n",
    "n_layers=[1,2,3]\n",
    "learning_rate=[0.01,0.001,0.0001,0.00001]\n",
    "batch_size=[16,32,64,128]\n",
    "activation_function=['relu','elu','tanh','sigmoid']\n",
    "all_hyperparams=[n_layers,learning_rate,batch_size,activation_function]\n",
    "population_size=6\n",
    "epochs=10\n",
    "sel_prt=2\n",
    "rand_prt=2\n",
    "generations=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gIF9UubTT5sy"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "# %matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense , Activation, Dropout,BatchNormalization,Input\n",
    "from tensorflow.keras.optimizers import Adam ,RMSprop\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import  backend as K\n",
    "import sys\n",
    "sys.path.append('./models/')\n",
    "from fcunet import fcunet_model\n",
    "from irnet import irnet_model\n",
    "from fcmnr import fcmnr_model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV,ParameterGrid, ParameterSampler\n",
    "import random\n",
    "from random import random,randrange\n",
    "from operator import itemgetters\n",
    "import timeit\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=2)\n",
    "random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQSFAbAdUHj2"
   },
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IL1-0AKdUJFb",
    "outputId": "1681258f-793e-4573-866a-e547ee15f1c9"
   },
   "outputs": [],
   "source": [
    "# import dataset\n",
    "# from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# load dataset\n",
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "# count the number of unique train labels\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"Train labels: \", dict(zip(unique, counts)))\n",
    "\n",
    "\n",
    "# count the number of unique test labels\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(\"\\nTest labels: \", dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "tKsz27QTURG2",
    "outputId": "0d1d2811-6292-4952-a250-42f4cefc24c4"
   },
   "outputs": [],
   "source": [
    "# sample 25 mnist digits from train dataset\n",
    "indexes = np.random.randint(0, x_train.shape[0], size=25)\n",
    "images = x_train[indexes]\n",
    "labels = y_train[indexes]\n",
    "\n",
    "\n",
    "# plot the 25 mnist digits\n",
    "plt.figure(figsize=(5,5))\n",
    "for i in range(len(indexes)):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    image = images[i]\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()\n",
    "plt.savefig(\"mnist-samples.png\")\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2vNTjW8UV94"
   },
   "source": [
    "Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OBqAi9AUaMt"
   },
   "outputs": [],
   "source": [
    "\n",
    "num_labels = len(np.unique(y_train))\n",
    "# convert to one-hot vector\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLzyFp1vU9RS"
   },
   "source": [
    "Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "suNGBU5NU5rI",
    "outputId": "216f4cf0-5dde-49e0-b2f0-94ce807baade"
   },
   "outputs": [],
   "source": [
    "# image dimensions (assumed square)\n",
    "image_size = x_train.shape[1]\n",
    "input_size = image_size * image_size\n",
    "print(input_size)\n",
    "# resize and normalize\n",
    "x_train = np.reshape(x_train, [-1, input_size])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = np.reshape(x_test, [-1, input_size])\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyk2FMPXVEeZ"
   },
   "source": [
    "Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NLfcBoyp_6w0"
   },
   "outputs": [],
   "source": [
    "def create_model(num_layers=2,hidden_units_start=256,activation='relu'):\n",
    "\n",
    "    input_vec = Input(shape=input_size)\n",
    "    x1=Dense(hidden_units_start,kernel_initializer=initializer)(input_vec)\n",
    "    x2=Activation(activation)(x1)\n",
    "    x3=Dropout(dropout,seed=2)(x2)\n",
    "    for layer in range(num_layers-1):\n",
    "        x4=Dense(hidden_units_start,kernel_initializer=initializer)(x3)\n",
    "        x5=Activation(activation)(x4)\n",
    "        x3=Dropout(dropout,seed=2)(x5)\n",
    "    x6=Dense(num_labels,kernel_initializer=initializer)(x3)\n",
    "    x7=Activation('softmax')(x6)\n",
    "\n",
    "    model=Model(input_vec,x7)\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmdC3fNTz0nY"
   },
   "outputs": [],
   "source": [
    "#INITIALIZE POPULATION\n",
    "\n",
    "def initialize_population(population_size,num_layers,hidden_units_start,activation):\n",
    "\n",
    "  param_grid = dict(num_layers=num_layers,hidden_units_start=hidden_units_start,activation=activation)\n",
    "  grid_search_population=list(ParameterSampler(param_grid,population_size))\n",
    "\n",
    "  potential_num_layers=[]\n",
    "  potential_hidden_units_start=[]\n",
    "  potential_activation=[]\n",
    "\n",
    "  for i in range(0,population_size):\n",
    "    potential_num_layers.insert(0,grid_search_population[i]['num_layers'])\n",
    "    potential_hidden_units_start.insert(0,grid_search_population[i]['hidden_units_start'])\n",
    "    potential_activation.insert(0,grid_search_population[i]['activation'])\n",
    "\n",
    "  return potential_num_layers,potential_hidden_units_start,potential_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATE FITNESS\n",
    "def evaluate_fitness(input_shape,n_layers,activation_function,learning_rate,batch_size,hp_dataset_name,weights_name,max_epochs,patience_epochs):\n",
    "  #CREATE MODEL\n",
    "  model=fcunet_model(n_layers,input_shape,activation_function,learning_rate) \n",
    "\n",
    "  start_time = timeit.default_timer()\n",
    "  history = model.fit(xtrain,ytrain,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=max_epochs,\n",
    "                      callbacks=[EarlyStopping(patience=patience_epochs)],validation_data=(xvalid,yvalid))\n",
    "  end_time = timeit.default_timer()\n",
    "\n",
    "  #EVALUATE MODEL\n",
    "  prediction=model.predict(xtest)\n",
    "  mae_test=mean_absolute_error(ytest,prediction)\n",
    "\n",
    "\n",
    "  #SAVE THE WEIGHTS\n",
    "  model.save(weights_folder+weights_name+\".h5\")\n",
    "\n",
    "  #SAVE THE HYPERPARAMS AND THE METRIC\n",
    "  with open(hp_dataset_name, mode='a+') as hp_dataset:\n",
    "      hp_dataset_writer=csv.writer(hp_dataset,delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "      hp_dataset_writer.writerow([architecture_name,\n",
    "                              problem_type,\n",
    "                              num_features,\n",
    "                              training_and_validation_samples,\n",
    "                              n_layers,\n",
    "                              input_shape,\n",
    "                              activation_function,\n",
    "                              learning_rate,\n",
    "                              batch_size,\n",
    "                              str(len(history.history['loss'])),\n",
    "                              end_time-start_time,\n",
    "                              mae_test\n",
    "                              ])\n",
    "  return mae_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolve the hyperparameters\n",
    "# Selection\n",
    "\n",
    "def selection(evaluated_hparams,sel_prt,rand_prt,population):\n",
    "    sorted_evaluated_params=sorted(evaluated_hparams,key=itemgetter('metric'),reverse=True)\n",
    "    if(sel_prt+rand_prt>=len(population[0])):\n",
    "      print(\"WARNING: Selections are bigger thant current population\")\n",
    "      print(\"WARNING: Random selection may not be taken\")\n",
    "\n",
    "    top_selection=[]\n",
    "    for i in range(sel_prt):\n",
    "      top_selection.insert(len(top_selection),sorted_evaluated_params[i]['hparam'])\n",
    "\n",
    "    rand_selection=[]\n",
    "    i=0\n",
    "    while(i < rand_prt):\n",
    "      if(len(rand_selection)+len(top_selection)>=len(population[0])):\n",
    "        break\n",
    "\n",
    "      rand_hparam=randrange(len(population[0]))\n",
    "      print(\"Generated random {}.\".format(rand_hparam))\n",
    "      if(rand_hparam in top_selection or rand_hparam in rand_selection):\n",
    "        continue\n",
    "\n",
    "      rand_selection.insert(0,rand_hparam)\n",
    "      i=i+1\n",
    "    return top_selection,rand_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CROSS-OVER OPERATION\n",
    "\n",
    "def crossover(p1,p2,population):\n",
    "    child_potential_num_layers=[]\n",
    "    child_potential_hidden_units_start=[]\n",
    "    child_potential_activation=[]\n",
    "    \n",
    "    #child1\n",
    "    child_potential_num_layers.insert(0,population[0][p1])\n",
    "    child_potential_hidden_units_start.insert(0,population[1][p2])\n",
    "    child_potential_activation.insert(0,population[2][p1])\n",
    "    \n",
    "    #child2\n",
    "    child_potential_num_layers.insert(0,population[0][p2])\n",
    "    child_potential_hidden_units_start.insert(0,population[1][p1])\n",
    "    child_potential_activation.insert(0,population[2][p2])\n",
    "    \n",
    "    #child3\n",
    "    child_potential_num_layers.insert(0,population[0][p1])\n",
    "    child_potential_hidden_units_start.insert(0,population[1][p1])\n",
    "    child_potential_activation.insert(0,population[2][p2])\n",
    "    \n",
    "    #child4\n",
    "    child_potential_num_layers.insert(0,population[0][p2])\n",
    "    child_potential_hidden_units_start.insert(0,population[1][p2])\n",
    "    child_potential_activation.insert(0,population[2][p1])\n",
    "    \n",
    "    child_hparams=[child_potential_num_layers,child_potential_hidden_units_start,child_potential_activation]\n",
    "    return child_hparams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MUTATION\n",
    "def mutation(population,selected):\n",
    "    selected_hyperparam=randrange(len(all_hyperparams))\n",
    "    selected_value=randrange(len(all_hyperparams[selected_hyperparam]))\n",
    "    population[selected_hyperparam][selected]=all_hyperparams[selected_hyperparam][selected_value]\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OWN RANDOM GRIDSEARCH\n",
    "def random_gridsearch():\n",
    "    dict_all_hyperparams=dict(num_layers=num_layers,hidden_units_start=hidden_units_start,activation=activation)\n",
    "    r_grid_search_population=list(ParameterSampler(dict_all_hyperparams,population_size))\n",
    "    RGS_evaluated_hparams=[]\n",
    "    for i in range(len(r_grid_search_population)):\n",
    "            metric=evaluate_fitness(r_grid_search_population[i]['num_layers'],\n",
    "                                    r_grid_search_population[i]['hidden_units_start'],\n",
    "                                    r_grid_search_population[i]['activation'])\n",
    "            RGS_evaluated_hparams.insert(len(RGS_evaluated_hparams),{\"hparam\":i,\"metric\":metric})\n",
    "    rgs_top_hparam=sorted(RGS_evaluated_hparams,key=itemgetter('metric'),reverse=True)[0]['hparam']\n",
    "    return sorted(RGS_evaluated_hparams,key=itemgetter('metric'),reverse=True)[0]['metric'],r_grid_search_population[rgs_top_hparam]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OWN GRIDSEARCH\n",
    "def gridsearch():\n",
    "    dict_all_hyperparams=dict(num_layers=num_layers,hidden_units_start=hidden_units_start,activation=activation)\n",
    "    grid_search_population=list(ParameterGrid(dict_all_hyperparams))\n",
    "    GS_evaluated_hparams=[]\n",
    "    for i in range(len(grid_search_population)):\n",
    "            metric=evaluate_fitness(grid_search_population[i]['num_layers'],\n",
    "                                    grid_search_population[i]['hidden_units_start'],\n",
    "                                    grid_search_population[i]['activation'])\n",
    "            GS_evaluated_hparams.insert(len(GS_evaluated_hparams),{\"hparam\":i,\"metric\":metric})\n",
    "    gs_top_hparam=sorted(GS_evaluated_hparams,key=itemgetter('metric'),reverse=True)[0]['hparam']\n",
    "    return GS_evaluated_hparams,sorted(GS_evaluated_hparams,key=itemgetter('metric'),reverse=True)[0]['metric'],grid_search_population[gs_top_hparam]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENETIC ALGORITHM\n",
    "# MAIN\n",
    "# initialize population\n",
    "\n",
    "def genetic_algorithm_main(population_size):\n",
    "    p_num_layers,p_hidden_units_start,p_activation=initialize_population(population_size=population_size,\n",
    "                                                                         num_layers=num_layers,\n",
    "                                                                         hidden_units_start=hidden_units_start,\n",
    "                                                                         activation=activation)\n",
    "    population=[p_num_layers,p_hidden_units_start,p_activation]\n",
    "    print(\"Initial population\",population)\n",
    "    final_hyperparam=[]\n",
    "    # evaluate hyperparams\n",
    "    for generation in range(generations):\n",
    "        evaluated_hparams=[]\n",
    "        for i in range(population_size):\n",
    "            metric=evaluate_fitness(population[0][i],population[1][i],population[2][i])\n",
    "            evaluated_hparams.insert(0,{\"hparam\":i,\"metric\":metric})\n",
    "\n",
    "        #SELECTION\n",
    "        top_selection,rand_selection=selection(evaluated_hparams,sel_prt,rand_prt,population)\n",
    "\n",
    "\n",
    "        # CROSS-OVER\n",
    "        p1,p2=random.sample(range(0,len(top_selection)+len(rand_selection)),2)\n",
    "        child_hyperparams=crossover(p1,p2,population)\n",
    "\n",
    "        #CREATE NEW POPULATION\n",
    "        new_population=[[population[0][i] for i in top_selection],\n",
    "                          [population[1][i] for i in top_selection],\n",
    "                          [population[2][i] for i in top_selection]]\n",
    "\n",
    "        new_population[0]=[*new_population[0],\n",
    "                                    *[population[0][i] for i in rand_selection],\n",
    "                                   *child_hyperparams[0]]\n",
    "        new_population[1]=[*new_population[1],\n",
    "                                    *[population[1][i] for i in rand_selection],\n",
    "                                   *child_hyperparams[1]]\n",
    "        new_population[2]=[*new_population[2],\n",
    "                                    *[population[2][i] for i in rand_selection],\n",
    "                                   *child_hyperparams[2]]\n",
    "\n",
    "        # MUTATION\n",
    "        selected_to_mutate=randrange(len(top_selection)+len(rand_selection)+len(child_hyperparams[0]))\n",
    "        mutation(new_population,selected_to_mutate)\n",
    "\n",
    "        if (generation+1)==generations:\n",
    "            for  hyperparam in  population:\n",
    "                final_hyperparam.insert(len(population),hyperparam[top_selection[0]])\n",
    "\n",
    "        population=new_population\n",
    "        population_size=len(population[0])\n",
    "\n",
    "    return evaluated_hparams,sorted(evaluated_hparams,key=itemgetter('metric'),reverse=True)[0]['metric'],final_hyperparam\n",
    "    \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genetic_algorithm_main\n",
    "# %%capture --no-stderr\n",
    "start_time = timeit.default_timer()\n",
    "all_ga,top_ga, hparams_ga = genetic_algorithm_main(population_size)\n",
    "stop_time = timeit.default_timer()\n",
    "ga_time=stop_time - start_time\n",
    "\n",
    "print(top_ga, hparams_ga,ga_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_gridsearch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-94110acf5f7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# %%capture --no-stderr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtop_rgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams_rgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_gridsearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mstop_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrgs_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random_gridsearch' is not defined"
     ]
    }
   ],
   "source": [
    "# random_gridsearch\n",
    "# %%capture --no-stderr\n",
    "start_time = timeit.default_timer()\n",
    "top_rgs, hparams_rgs = random_gridsearch()\n",
    "stop_time = timeit.default_timer()\n",
    "rgs_time=stop_time - start_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "# %%capture --no-stderr\n",
    "if(run_gs):\n",
    "    start_time = timeit.default_timer()\n",
    "    all_gs,top_gs, hparams_gs = gridsearch()\n",
    "    stop_time = timeit.default_timer()\n",
    "    gs_time=stop_time - start_time\n",
    "    print(top_gs, hparams_gs,gs_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_gs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5027e6d4933e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_gs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mall_gs_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_gs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mall_ga_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_ga\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_gs' is not defined"
     ]
    }
   ],
   "source": [
    "# Save and read results\n",
    "\n",
    "if(run_gs):all_gs_sorted=sorted(all_gs,key=itemgetter('metric'),reverse=True)\n",
    "all_ga_sorted=sorted(all_ga,key=itemgetter('metric'),reverse=True)\n",
    "with open('results-pop'+str(population_size), 'wb') as fp:\n",
    "    pickle.dump([\"GA:\",top_ga,hparams_ga,ga_time], fp)\n",
    "    pickle.dump([\"RGS:\",top_rgs, hparams_rgs,rgs_time], fp)\n",
    "    if(run_gs):pickle.dump([\"GS:\",top_gs, hparams_gs,gs_time], fp)\n",
    "    if(run_gs):pickle.dump([\"\\n GS hparams:\",all_gs_sorted],fp)\n",
    "    pickle.dump([\"\\n GA hparams:\",all_ga_sorted],fp)\n",
    "with open ('results-pop'+str(population_size), 'rb') as fp:\n",
    "    try:\n",
    "        while True:\n",
    "            print(pickle.load(fp))\n",
    "    except EOFError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NN MNIST  - GA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('gpu2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "0a0cbb9f60c8eee06fcff2a3e781b787b625e426ae10e4b3b3444b8ac7b4e16c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
