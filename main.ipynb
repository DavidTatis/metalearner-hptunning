{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_meta_data(data_file_name,dataset_column_names,x_column_names,to_categorical_column_names,metric_name,error_metric=True):\n",
    "    dataset=pd.read_csv(data_file_name,names=dataset_column_names)\n",
    "    y=np.zeros(len(dataset))\n",
    "    print(len(y))\n",
    "    #CALCULATE THE Y\n",
    "    if error_metric:\n",
    "        min_error=dataset.loc[dataset[metric_name].idxmin()][metric_name]\n",
    "        error_ratio=min_error/dataset[metric_name]\n",
    "        y=error_ratio\n",
    "    else:\n",
    "        max_acc=dataset.loc[dataset[metric_name].idxmax()][metric_name]\n",
    "        acc_ratio=max_acc/dataset[metric_name]\n",
    "        y=acc_ratio\n",
    "    \n",
    "    x=dataset[x_column_names]\n",
    "\n",
    "    dummies = pd.get_dummies(x[to_categorical_column_names[:]],prefix=[''],prefix_sep=[''])\n",
    "    x=x.drop(to_categorical_column_names,axis=1)\n",
    "    x=pd.concat([x,dummies],axis=1)\n",
    "    x.head()\n",
    "    return x,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta learner Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metamodel(x,y):\n",
    "    regr = RandomForestRegressor(random_state=0)\n",
    "    regr.fit(x,y)\n",
    "    return regr\n",
    "\n",
    "def create_hp_space(num_features,training_samples,n_layers,learning_rate,batch_size,activation_function):\n",
    "    #CREATE THE HYPERPARAMETER SPACE\n",
    "    dict_all_hyperparams=dict(num_features=num_features,\n",
    "                                training_samples=training_samples,\n",
    "                                n_layers=n_layers,\n",
    "                                learning_rate=learning_rate,\n",
    "                                batch_size=batch_size,\n",
    "                                activation_function=activation_function)\n",
    "\n",
    "    grid_search_population=pd.DataFrame(ParameterGrid(dict_all_hyperparams))\n",
    "    return grid_search_population\n",
    "    \n",
    "def predict_hp_space(grid_search_population,regr,to_categorical_column_names,to_categorical_values,x_column_names):\n",
    "    #PREPROCESS THE DATA TO BE PREDICTED BY THE METALEARNER\n",
    "    dummies2 = pd.get_dummies(grid_search_population[to_categorical_column_names[:]],prefix=[''],prefix_sep=[''])\n",
    "    x_test=pd.concat([grid_search_population[x_column_names],dummies2],axis=1)\n",
    "    x_test=x_test.drop(to_categorical_column_names,axis=1)\n",
    "    #PREDICTION OF THE HYPERPARAMETER SPACE\n",
    "    predictions= pd.DataFrame(regr.predict(x_test))\n",
    "    x_test_predicted=x_test.loc[:]\n",
    "\n",
    "    #REVERSE THE CATEGORICAL OF THE ACTIVATION FUNCTION\n",
    "    x_test_predicted[\"activation_function\"]=x_test_predicted[to_categorical_values].idxmax(axis=1)\n",
    "    x_test_predicted=x_test_predicted.drop(to_categorical_values,axis=1)\n",
    "\n",
    "    x_test_predicted[\"y\"]=pd.DataFrame(regr.predict(x_test))\n",
    "    x_test_predicted=x_test_predicted.sort_values(\"y\",ascending=False)\n",
    "    return x_test_predicted\n",
    "    \n",
    "def get_top_hp_combination(n_top_hp_to_select,x_test_predicted):\n",
    "\n",
    "    #SEARCH FOR THE TOP COMBINATION\n",
    "    top_lr=[]\n",
    "    top_bz=[]\n",
    "    top_layers=[]\n",
    "    top_af=[]\n",
    "    search=True\n",
    "    topi=1\n",
    "    finish_order=[]\n",
    "    while(search): \n",
    "        if len(top_lr)<n_top_hp_to_select:\n",
    "            top_lr=x_test_predicted.head(topi)[\"learning_rate\"].unique()\n",
    "        else:\n",
    "            if(\"learning_rate\" not in finish_order): finish_order.append(\"learning_rate\")\n",
    "        \n",
    "        if len(top_bz)<n_top_hp_to_select:\n",
    "            top_bz=x_test_predicted.head(topi)[\"batch_size\"].unique()\n",
    "        else:\n",
    "            if (\"batch_size\" not in finish_order): finish_order.append(\"batch_size\")\n",
    "        \n",
    "        if len(top_layers)<n_top_hp_to_select:\n",
    "            top_layers=x_test_predicted.head(topi)[\"n_layers\"].unique()\n",
    "        else:\n",
    "            if (\"n_layers\" not in finish_order): finish_order.append(\"n_layers\")\n",
    "        \n",
    "        if len(top_af)<n_top_hp_to_select:\n",
    "            top_af=x_test_predicted.head(topi)[\"activation_function\"].unique()\n",
    "        else:\n",
    "            if (\"activation_function\" not in finish_order): finish_order.append(\"activation_function\")\n",
    "        \n",
    "        topi +=1\n",
    "        if len(top_lr)<n_top_hp_to_select or len(top_bz)<n_top_hp_to_select or len(top_layers)<n_top_hp_to_select or len(top_af)<n_top_hp_to_select:\n",
    "            search=True\n",
    "        else:\n",
    "            if(\"learning_rate\" not in finish_order): finish_order.append(\"learning_rate\")\n",
    "            if (\"batch_size\" not in finish_order): finish_order.append(\"batch_size\")\n",
    "            if (\"n_layers\" not in finish_order): finish_order.append(\"n_layers\")\n",
    "            if (\"activation_function\" not in finish_order): finish_order.append(\"activation_function\")\n",
    "            search=False\n",
    "    \n",
    "    return top_lr,top_bz,top_layers,top_af,finish_order\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_features</th>\n",
       "      <th>training_samples</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.983194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.982024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.981702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.981559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.976312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.975423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.975229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.974431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.973998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.972326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.971169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.969612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.969532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.966637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.966092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.965983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.965711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.963176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.963134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.962737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.961130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.958303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.953392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.952527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.930908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.930206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.926821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.926795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.926098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.924909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.923432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.922832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.922784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.920360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.919367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.918722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.915043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.913991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.909455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>29</td>\n",
       "      <td>240122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.907154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_features  training_samples  n_layers  learning_rate  batch_size  \\\n",
       "37             29            240122         2          0.010         128   \n",
       "26             29            240122         3          0.010          64   \n",
       "38             29            240122         3          0.010         128   \n",
       "25             29            240122         2          0.010          64   \n",
       "122            29            240122         3          0.010          64   \n",
       "133            29            240122         2          0.010         128   \n",
       "121            29            240122         2          0.010          64   \n",
       "134            29            240122         3          0.010         128   \n",
       "74             29            240122         3          0.010          64   \n",
       "86             29            240122         3          0.010         128   \n",
       "169            29            240122         2          0.010          64   \n",
       "181            29            240122         2          0.010         128   \n",
       "85             29            240122         2          0.010         128   \n",
       "168            29            240122         1          0.010          64   \n",
       "73             29            240122         2          0.010          64   \n",
       "24             29            240122         1          0.010          64   \n",
       "170            29            240122         3          0.010          64   \n",
       "182            29            240122         3          0.010         128   \n",
       "36             29            240122         1          0.010         128   \n",
       "120            29            240122         1          0.010          64   \n",
       "180            29            240122         1          0.010         128   \n",
       "132            29            240122         1          0.010         128   \n",
       "72             29            240122         1          0.010          64   \n",
       "84             29            240122         1          0.010         128   \n",
       "14             29            240122         3          0.010          32   \n",
       "13             29            240122         2          0.010          32   \n",
       "110            29            240122         3          0.010          32   \n",
       "62             29            240122         3          0.010          32   \n",
       "109            29            240122         2          0.010          32   \n",
       "61             29            240122         2          0.010          32   \n",
       "12             29            240122         1          0.010          32   \n",
       "157            29            240122         2          0.010          32   \n",
       "158            29            240122         3          0.010          32   \n",
       "108            29            240122         1          0.010          32   \n",
       "60             29            240122         1          0.010          32   \n",
       "156            29            240122         1          0.010          32   \n",
       "125            29            240122         3          0.001          64   \n",
       "137            29            240122         3          0.001         128   \n",
       "29             29            240122         3          0.001          64   \n",
       "77             29            240122         3          0.001          64   \n",
       "\n",
       "    activation_function         y  \n",
       "37                 relu  0.983194  \n",
       "26                 relu  0.982024  \n",
       "38                 relu  0.981702  \n",
       "25                 relu  0.981559  \n",
       "122                tanh  0.976312  \n",
       "133                tanh  0.975423  \n",
       "121                tanh  0.975229  \n",
       "134                tanh  0.974431  \n",
       "74                  elu  0.973998  \n",
       "86                  elu  0.972326  \n",
       "169             sigmoid  0.971169  \n",
       "181             sigmoid  0.969612  \n",
       "85                  elu  0.969532  \n",
       "168             sigmoid  0.966637  \n",
       "73                  elu  0.966092  \n",
       "24                 relu  0.965983  \n",
       "170             sigmoid  0.965711  \n",
       "182             sigmoid  0.963176  \n",
       "36                 relu  0.963134  \n",
       "120                tanh  0.962737  \n",
       "180             sigmoid  0.961130  \n",
       "132                tanh  0.958303  \n",
       "72                  elu  0.953392  \n",
       "84                  elu  0.952527  \n",
       "14                 relu  0.930908  \n",
       "13                 relu  0.930206  \n",
       "110                tanh  0.926821  \n",
       "62                  elu  0.926795  \n",
       "109                tanh  0.926098  \n",
       "61                  elu  0.924909  \n",
       "12                 relu  0.923432  \n",
       "157             sigmoid  0.922832  \n",
       "158             sigmoid  0.922784  \n",
       "108                tanh  0.920360  \n",
       "60                  elu  0.919367  \n",
       "156             sigmoid  0.918722  \n",
       "125                tanh  0.915043  \n",
       "137                tanh  0.913991  \n",
       "29                 relu  0.909455  \n",
       "77                  elu  0.907154  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#DATASET NAMES    \n",
    "def meta_learner(n_top_hp_to_select):\n",
    "    dataset_column_names=[\"architecture\",\"task\",\"num_features\",\"training_samples\",\n",
    "                \"n_layers\", \"input_shape\",\"activation_function\",\n",
    "                \"learning_rate\", \"batch_size\", \"loss\",\"fit_time\",\"mae\"]\n",
    "    x_column_names=[\"num_features\",\"training_samples\",\n",
    "                            \"n_layers\",\"activation_function\",\n",
    "                            \"learning_rate\", \"batch_size\",]\n",
    "    metric_name=\"mae\"\n",
    "    to_categorical_column_names=[\"activation_function\"]\n",
    "    data_file_name=\"./data/1d_irnet.csv\"\n",
    "    #HYPERPARAMETERS TO EVALUATE\n",
    "    num_features=[29]\n",
    "    training_samples=[240122]\n",
    "\n",
    "    n_layers=[1,2,3]\n",
    "    learning_rate=[0.01,0.001,0.0001,0.00001]\n",
    "    batch_size=[16,32,64,128]\n",
    "    activation_function=['relu','elu','tanh','sigmoid']\n",
    "    n_top_hp_to_select=2\n",
    "\n",
    "    x,y=load_meta_data(data_file_name,dataset_column_names,x_column_names,to_categorical_column_names,metric_name,error_metric=True)                              \n",
    "    model=create_metamodel(x,y)\n",
    "    gs_population=create_hp_space(num_features,training_samples,n_layers,learning_rate,batch_size,activation_function)\n",
    "    predictions=predict_hp_space(gs_population,model,to_categorical_column_names,activation_function,x_column_names)\n",
    "\n",
    "    top_lr,top_bz,top_layers,top_af,finish_order=get_top_hp_combination(n_top_hp_to_select,predictions)\n",
    "    return top_lr,top_bz,top_layers,top_af,finish_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01   0.001  0.0001] [128  64  32] [2 3 1] ['relu' 'tanh' 'elu'] ['activation_function', 'n_layers', 'batch_size', 'learning_rate']\n"
     ]
    }
   ],
   "source": [
    "top_lr,top_bz,top_layers,top_af,finish_order=get_top_hp_combination(3,predictions)\n",
    "\n",
    "print(top_lr,top_bz,top_layers,top_af,finish_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('gpu2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a0cbb9f60c8eee06fcff2a3e781b787b625e426ae10e4b3b3444b8ac7b4e16c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
